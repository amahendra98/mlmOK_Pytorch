{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "from gym.wrappers import Monitor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import pow, add, mul, div, sqrt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tensorboard import program"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import datareader\n",
    "from time_recorder import time_keeper\n",
    "from FastDataLoader import FastTensorDataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from plotting_functions import compare_spectra"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def read_data( x_range, y_range, geoboundary,  batch_size=128,\n",
    "                 data_dir=os.path.abspath(''), rand_seed=1234, normalize_input = True, test_ratio = 0.999):\n",
    "    \"\"\"\n",
    "      :param input_size: input size of the arrays\n",
    "      :param output_size: output size of the arrays\n",
    "      :param x_range: columns of input data in the txt file\n",
    "      :param y_range: columns of output data in the txt file\n",
    "      :param cross_val: number of cross validation folds\n",
    "      :param val_fold: which fold to be used for validation\n",
    "      :param batch_size: size of the batch read every time\n",
    "      :param shuffle_size: size of the batch when shuffle the dataset\n",
    "      :param data_dir: parent directory of where the data is stored, by default it's the current directory\n",
    "      :param rand_seed: random seed\n",
    "      :param test_ratio: if this is not 0, then split test data from training data at this ratio\n",
    "                         if this is 0, use the dataIn/eval files to make the test set\n",
    "      \"\"\"\n",
    "\n",
    "    # Import data files\n",
    "    print('Importing data files...')\n",
    "\n",
    "    ftrTrain, lblTrain = datareader.importData(os.path.join(data_dir, 'dataIn'), x_range, y_range)\n",
    "    if (test_ratio > 0):\n",
    "        print(\"Splitting data into training and test sets with a ratio of:\", str(test_ratio))\n",
    "        ftrTrain, ftrTest, lblTrain, lblTest = train_test_split(ftrTrain, lblTrain,\n",
    "                                                                test_size=test_ratio, random_state=rand_seed)\n",
    "        print('Total number of training samples is {}'.format(len(ftrTrain)))\n",
    "        print('Total number of test samples is {}'.format(len(ftrTest)))\n",
    "        print('Length of an output spectrum is {}'.format(len(lblTest[0])))\n",
    "    else:\n",
    "        print(\"Using separate file from dataIn/Eval as test set\")\n",
    "        ftrTest, lblTest = datareader.importData(os.path.join(data_dir, 'dataIn', 'eval'), x_range, y_range)\n",
    "\n",
    "    # print('Total number of training samples is {}'.format(len(ftrTrain)))\n",
    "    # print('Total number of test samples is {}'.format(len(ftrTest)))\n",
    "    # print('Length of an output spectrum is {}'.format(len(lblTest[0])))\n",
    "    # print('downsampling output curves')\n",
    "    # resample the output curves so that there are not so many output points\n",
    "    if len(lblTrain[0]) > 2000:                                 # For Omar data set\n",
    "        lblTrain = lblTrain[::, len(lblTest[0])-1800::6]\n",
    "        lblTest = lblTest[::, len(lblTest[0])-1800::6]\n",
    "\n",
    "    # print('length of downsampled train spectra is {} for first, {} for final, '.format(len(lblTrain[0]),\n",
    "    #                                                                                    len(lblTrain[-1])),\n",
    "    #       'set final layer size to be compatible with this number')\n",
    "\n",
    "    print('Generating torch datasets')\n",
    "    assert np.shape(ftrTrain)[0] == np.shape(lblTrain)[0]\n",
    "    assert np.shape(ftrTest)[0] == np.shape(lblTest)[0]\n",
    "\n",
    "    # Normalize the data if instructed using boundary\n",
    "    if normalize_input:\n",
    "        ftrTrain[:,0:4] = (ftrTrain[:,0:4] - (geoboundary[0] + geoboundary[1]) / 2)/(geoboundary[1] - geoboundary[0]) * 2\n",
    "        ftrTest[:,0:4] = (ftrTest[:,0:4] - (geoboundary[0] + geoboundary[1]) / 2)/(geoboundary[1] - geoboundary[0]) * 2\n",
    "        ftrTrain[:,4:] = (ftrTrain[:,4:] - (geoboundary[2] + geoboundary[3]) / 2)/(geoboundary[3] - geoboundary[2]) * 2\n",
    "        ftrTest[:,4:] = (ftrTest[:,4:] - (geoboundary[2] + geoboundary[3]) / 2)/(geoboundary[3] - geoboundary[2]) * 2\n",
    "\n",
    "    # train_data = datareader.MetaMaterialDataSet(ftrTrain, lblTrain, bool_train= True)\n",
    "    # test_data = datareader.MetaMaterialDataSet(ftrTest, lblTest, bool_train= False)\n",
    "    # train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "    # test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    return ftrTest, lblTest\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data files...\n",
      "['ToyModelSim_e2_with_params_16.csv', 'ToyModelSim_e2_with_params_3.csv', 'ToyModelSim_e2_with_params_10.csv', 'ToyModelSim_e2_with_params_12.csv', 'ToyModelSim_e2_with_params_15.csv', 'ToyModelSim_e2_with_params_11.csv', 'ToyModelSim_e2_with_params_4.csv', 'ToyModelSim_e2_with_params_23.csv', 'ToyModelSim_e2_with_params_7.csv', 'ToyModelSim_e2_with_params_25.csv', 'ToyModelSim_e2_with_params_9.csv', 'ToyModelSim_e2_with_params_8.csv', 'ToyModelSim_e2_with_params_6.csv', 'ToyModelSim_e2_with_params_13.csv', 'ToyModelSim_e2_with_params_2.csv', 'ToyModelSim_e2_with_params_24.csv', 'ToyModelSim_e2_with_params_22.csv', 'ToyModelSim_e2_with_params_5.csv', 'ToyModelSim_e2_with_params_1.csv', 'ToyModelSim_e2_with_params_18.csv', 'ToyModelSim_e2_with_params_17.csv', 'ToyModelSim_e2_with_params_19.csv', 'ToyModelSim_e2_with_params_21.csv', 'ToyModelSim_e2_with_params_20.csv', 'ToyModelSim_e2_with_params_14.csv']\n",
      "Splitting data into training and test sets with a ratio of: 0.999\n",
      "Total number of training samples is 50\n",
      "Total number of test samples is 49950\n",
      "Length of an output spectrum is 300\n",
      "Generating torch datasets\n"
     ]
    }
   ],
   "source": [
    "import flagreader\n",
    "flags = flagreader.read_flag()\n",
    "batch_size = 4096\n",
    "ftrTest, lblTest = read_data(x_range=flags.x_range,\n",
    "                                                     y_range=[i for i in range(20 , 320 )],\n",
    "                                                     geoboundary=flags.geoboundary,\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     normalize_input=flags.normalize_input,\n",
    "                                                     data_dir=flags.data_dir,\n",
    "                                                     test_ratio=0.999)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def reload_data(ftrTest,lblTest):\n",
    "    # train_loader = FastTensorDataLoader(torch.from_numpy(ftrTrain),\n",
    "    #                                     torch.from_numpy(lblTrain), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = FastTensorDataLoader(torch.from_numpy(ftrTest),\n",
    "                                       torch.from_numpy(lblTest), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return test_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class LorentzNN(nn.Module):\n",
    "    def __init__(self, flags):\n",
    "        super(LorentzNN, self).__init__()\n",
    "        self.flags = flags\n",
    "\n",
    "        w_numpy = np.arange(flags.freq_low, flags.freq_high,\n",
    "                            (flags.freq_high - flags.freq_low) / self.flags.num_spec_points)\n",
    "\n",
    "        cuda = True if torch.cuda.is_available() else False\n",
    "        if cuda:\n",
    "            self.w = torch.tensor(w_numpy).cuda()\n",
    "        else:\n",
    "            self.w = torch.tensor(w_numpy)\n",
    "\n",
    "        self.linears = nn.ModuleList([])\n",
    "        for ind, fc_num in enumerate(flags.linear[0:-1]):\n",
    "            self.linears.append(nn.Linear(fc_num, flags.linear[ind + 1], bias=True))\n",
    "\n",
    "        layer_size = flags.linear[-1]\n",
    "        self.lin_w0 = nn.Linear(layer_size, self.flags.num_lorentz_osc, bias=False)\n",
    "        self.lin_wp = nn.Linear(layer_size, self.flags.num_lorentz_osc, bias=False)\n",
    "        self.lin_g = nn.Linear(layer_size, self.flags.num_lorentz_osc, bias=False)\n",
    "\n",
    "    def forward(self, G):\n",
    "        out = G\n",
    "        for ind, fc in enumerate(self.linears):\n",
    "            if ind <= len(self.linears):\n",
    "                out = F.relu(fc(out))\n",
    "\n",
    "        w0 = F.relu(self.lin_w0(out))\n",
    "        wp = F.relu(self.lin_wp(out))\n",
    "        g = F.relu(self.lin_g(out))\n",
    "\n",
    "        w0 = w0.unsqueeze(2) * 1\n",
    "        wp = wp.unsqueeze(2) * 1\n",
    "        g = g.unsqueeze(2) * 0.1\n",
    "\n",
    "        w0 = w0.expand(out.size(0), self.flags.num_lorentz_osc, self.flags.num_spec_points)\n",
    "        wp = wp.expand_as(w0)\n",
    "        g = g.expand_as(w0)\n",
    "        w_expand = self.w.expand_as(g)\n",
    "\n",
    "        e2 = div(mul(pow(wp, 2), mul(w_expand, g)),\n",
    "                 add(pow(add(pow(w0, 2), -pow(w_expand, 2)), 2), mul(pow(w_expand, 2), pow(g, 2))))\n",
    "\n",
    "        e2 = torch.sum(e2, 1)\n",
    "        return e2.float()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "dir = '/home/omar/PycharmProjects/mlmOK_Pytorch/'\n",
    "tk = time_keeper(time_keeping_file=os.path.join(dir, 'training_time.txt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "\n",
    "        # nn.Conv2d weights are of shape [16, 1, 3, 3] i.e. # number of filters, 1, stride, stride\n",
    "        # nn.Conv2d bias is of shape [16] i.e. # number of filters\n",
    "\n",
    "        # nn.Linear weights are of shape [32, 24336] i.e. # number of input features, number of output features\n",
    "        # nn.Linear bias is of shape [32] i.e. # number of output features\n",
    "\n",
    "        if ((type(m) == nn.Linear) | (type(m) == nn.Conv2d)):\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            if m.bias:\n",
    "                m.bias.data.fill_(0.00)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def return_random_agents(num_agents):\n",
    "\n",
    "    agents = []\n",
    "    for _ in range(num_agents):\n",
    "\n",
    "        agent = LorentzNN(flags)\n",
    "\n",
    "        for param in agent.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        init_weights(agent)\n",
    "        agents.append(agent)\n",
    "\n",
    "\n",
    "    return agents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def run_agents(agents):\n",
    "\n",
    "    reward_agents = []\n",
    "\n",
    "    for agent_num, agent in enumerate(agents):\n",
    "        cuda = True if torch.cuda.is_available() else False\n",
    "        if cuda:\n",
    "            agent.cuda()\n",
    "        agent.eval()\n",
    "\n",
    "        eval_loss = []\n",
    "        with torch.no_grad():\n",
    "            for ind, (geometry, spectra) in enumerate(test_loader):\n",
    "                if cuda:\n",
    "                    geometry = geometry.cuda()\n",
    "                    spectra = spectra.cuda()\n",
    "                if (batch_size*(ind+1) < 20000):\n",
    "                    logit = agent(geometry)\n",
    "                    loss = nn.functional.mse_loss(logit, spectra)\n",
    "                    eval_loss.append(np.copy(loss.cpu().data.numpy()))\n",
    "                else:\n",
    "                    break\n",
    "        eval_avg_loss = np.mean(eval_loss)\n",
    "        # reward = 1/eval_avg_loss\n",
    "        # reward = math.exp(reward)-1\n",
    "        reward = -eval_avg_loss\n",
    "        if math.isnan(reward):\n",
    "            reward = 0\n",
    "        reward_agents.append(reward)\n",
    "        # print(agent_num)\n",
    "\n",
    "    return reward_agents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def return_average_score(agent, runs):\n",
    "    score = 0.\n",
    "    for i in range(runs):\n",
    "        score += run_agents([agent])[0]\n",
    "    return score/runs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def run_agents_n_times(agents, runs):\n",
    "    avg_score = []\n",
    "    for agent in agents:\n",
    "        avg_score.append(return_average_score(agent,runs))\n",
    "    return avg_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def mutate(agent):\n",
    "\n",
    "    child_agent = copy.deepcopy(agent)\n",
    "\n",
    "    mutation_power = 0.05 #hyper-parameter, set from https://arxiv.org/pdf/1712.06567.pdf\n",
    "    sparsity_index = 0.2\n",
    "    # for param in child_agent.parameters():\n",
    "    for layer_name, child in child_agent.named_children():\n",
    "        for param in child.parameters():\n",
    "            if(layer_name == 'lin_w0' or layer_name == 'lin_wp'\n",
    "                    or layer_name == 'lin_g'):\n",
    "                mutation_tensor = torch.randn_like(param)\n",
    "                mut_sorted,ind = torch.sort(mutation_tensor.view(-1,1))\n",
    "                limit = int((len(mut_sorted)-1)*(1-sparsity_index))\n",
    "                mutation_tensor[torch.abs(mutation_tensor) < mut_sorted[limit]] = 0\n",
    "                param += torch.randn_like(param) * mutation_power\n",
    "            else:\n",
    "                param += torch.randn_like(param) * mutation_power\n",
    "\n",
    "                # print(param)\n",
    "\n",
    "        # if(len(param.shape)==4): #weights of Conv2D\n",
    "        #     # a=1\n",
    "        #     for i0 in range(param.shape[0]):\n",
    "        #         for i1 in range(param.shape[1]):\n",
    "        #             for i2 in range(param.shape[2]):\n",
    "        #                 for i3 in range(param.shape[3]):\n",
    "        #\n",
    "        #                     param[i0][i1][i2][i3]+= mutation_power * np.random.randn()\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        # elif(len(param.shape)==2): #weights of linear layer\n",
    "        #     # param += np.random.rand(param.shape[0],param.shape[1]) * mutation_power\n",
    "        #\n",
    "        #     for i0 in range(param.shape[0]):\n",
    "        #         for i1 in range(param.shape[1]):\n",
    "        #\n",
    "        #             param[i0][i1]+= mutation_power * np.random.randn()\n",
    "        #\n",
    "        #\n",
    "        # elif(len(param.shape)==1): #biases of linear layer or conv layer\n",
    "        #     for i0 in range(param.shape[0]):\n",
    "        #\n",
    "        #         param[i0]+=mutation_power * np.random.randn()\n",
    "\n",
    "    return child_agent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def return_children(agents, sorted_parent_indexes, elite_index):\n",
    "\n",
    "    children_agents = []\n",
    "\n",
    "    #first take selected parents from sorted_parent_indexes and generate N-1 children\n",
    "    for i in range(len(agents)-1):\n",
    "\n",
    "        selected_agent_index = sorted_parent_indexes[np.random.randint(len(sorted_parent_indexes))]\n",
    "        children_agents.append(mutate(agents[selected_agent_index]))\n",
    "\n",
    "    #now add one elite\n",
    "    elite_child = add_elite(agents, sorted_parent_indexes, elite_index)\n",
    "    children_agents.append(elite_child)\n",
    "    elite_index=len(children_agents)-1 #it is the last one\n",
    "\n",
    "    return children_agents, elite_index\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def add_elite(agents, sorted_parent_indexes, elite_index=None, only_consider_top_n=10):\n",
    "\n",
    "    candidate_elite_index = sorted_parent_indexes[:only_consider_top_n]\n",
    "\n",
    "    if(elite_index is not None):\n",
    "        candidate_elite_index = np.append(candidate_elite_index,[elite_index])\n",
    "\n",
    "    top_score = None\n",
    "    top_elite_index = None\n",
    "\n",
    "    for i in candidate_elite_index:\n",
    "        score = return_average_score(agents[i],runs=1)\n",
    "        print(\"Score for elite i \", i, \" is \", score)\n",
    "\n",
    "        if(top_score is None):\n",
    "            top_score = score\n",
    "            top_elite_index = i\n",
    "        elif(score > top_score):\n",
    "            top_score = score\n",
    "            top_elite_index = i\n",
    "\n",
    "    print(\"Elite selected with index \",top_elite_index, \" and score\", top_score)\n",
    "\n",
    "    child_agent = copy.deepcopy(agents[top_elite_index])\n",
    "    return child_agent\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def start_tensorboard(model_path):\n",
    "\n",
    "    tb = program.TensorBoard()\n",
    "    log = SummaryWriter(model_path)\n",
    "    tb.configure(argv=[None, '--logdir', model_path])\n",
    "\n",
    "    return tb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def plot_elite(agent, log, gen):\n",
    "    cuda = True if torch.cuda.is_available() else False\n",
    "    if cuda:\n",
    "        agent.cuda()\n",
    "    agent.eval()\n",
    "\n",
    "    eval_loss = []\n",
    "    with torch.no_grad():\n",
    "        for ind, (geometry, spectra) in enumerate(test_loader):\n",
    "            if cuda:\n",
    "                geometry = geometry.cuda()\n",
    "                spectra = spectra.cuda()\n",
    "            if (batch_size*(ind+1) < 20000):\n",
    "                logit = agent(geometry)\n",
    "                loss = nn.functional.mse_loss(logit, spectra)\n",
    "                eval_loss.append(np.copy(loss.cpu().data.numpy()))\n",
    "            else:\n",
    "                break\n",
    "    eval_avg_loss = -np.mean(eval_loss)\n",
    "    log.add_scalar('Loss', eval_avg_loss, gen)\n",
    "    for k in range(10):\n",
    "        f = compare_spectra(Ypred=logit[k, :].cpu().data.numpy(), Ytruth=spectra[k, :].cpu().data.numpy(),\n",
    "                            xmin=flags.freq_low, xmax=flags.freq_high, num_points=flags.num_spec_points)\n",
    "        log.add_figure(tag='Test ' + str(k) +') Sample e2 Spectrum'.format(1),\n",
    "                                                    figure=f, global_step=gen)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard started at http://localhost:6008/\n",
      "\n",
      "\n",
      "Generation  0  | Mean rewards:  -56.902763  | Mean of top 5:  -56.041283\n",
      "Top  20  scores [153 433 120 309  67  12  87 168 265 210 489 371 442 152 419 227 480  53\n",
      " 115 357]\n",
      "Rewards for top:  [-55.927677, -56.002205, -56.03347, -56.099392, -56.143684, -56.23887, -56.259586, -56.261337, -56.26413, -56.266647, -56.296715, -56.298393, -56.304348, -56.318085, -56.327118, -56.32731, -56.34575, -56.348694, -56.348904, -56.35109]\n",
      "Score for elite i  153  is  -57.0632438659668\n",
      "Score for elite i  433  is  -57.08674621582031\n",
      "Score for elite i  120  is  -57.16672134399414\n",
      "Score for elite i  309  is  -56.91170883178711\n",
      "Score for elite i  67  is  -56.839237213134766\n",
      "Score for elite i  12  is  -57.308815002441406\n",
      "Score for elite i  87  is  -56.61870193481445\n",
      "Score for elite i  168  is  -56.44713592529297\n",
      "Score for elite i  265  is  -57.109867095947266\n",
      "Score for elite i  210  is  -56.66191864013672\n",
      "Elite selected with index  168  and score -56.44713592529297\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-24-eb53f342d0cc>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     29\u001B[0m     \u001B[0;31m# rewards = run_agents_n_times(agents, 1) #return average of 3 runs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 31\u001B[0;31m     \u001B[0mrewards\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrun_agents\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0magents\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     32\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m     \u001B[0;31m# sort by rewards\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-12-64d2014adc84>\u001B[0m in \u001B[0;36mrun_agents\u001B[0;34m(agents)\u001B[0m\n\u001B[1;32m     18\u001B[0m                     \u001B[0mlogit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0magent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgeometry\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m                     \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunctional\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmse_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mspectra\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m                     \u001B[0meval_loss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m                     \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# game_actions = 2 #2 actions possible: left or right\n",
    "\n",
    "#disable gradients as we will not use them\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# initialize N number of agents\n",
    "num_agents = 500\n",
    "agents = return_random_agents(num_agents)\n",
    "\n",
    "# How many top agents to consider as parents\n",
    "top_limit = 20\n",
    "\n",
    "# run evolution until X generations\n",
    "generations = 5\n",
    "\n",
    "elite_index = None\n",
    "\n",
    "model_path = '/home/omar/PycharmProjects/mlmOK_Pytorch/models/GA'\n",
    "tb = program.TensorBoard()\n",
    "log = SummaryWriter(model_path)\n",
    "tb.configure(argv=[None, '--logdir', model_path])\n",
    "url = tb.launch()\n",
    "print(\"TensorBoard started at %s\" % url)\n",
    "\n",
    "for generation in range(generations):\n",
    "\n",
    "    test_loader = reload_data(ftrTest,lblTest)\n",
    "    # return rewards of agents\n",
    "    # rewards = run_agents_n_times(agents, 1) #return average of 3 runs\n",
    "\n",
    "    rewards = run_agents(agents)\n",
    "\n",
    "    # sort by rewards\n",
    "    sorted_parent_indexes = np.argsort(rewards)[::-1][:top_limit] #reverses and gives top values (argsort sorts by ascending by default) https://stackoverflow.com/questions/16486252/is-it-possible-to-use-argsort-in-descending-order\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "\n",
    "    top_rewards = []\n",
    "    for best_parent in sorted_parent_indexes:\n",
    "        top_rewards.append(rewards[best_parent])\n",
    "\n",
    "    print(\"Generation \", generation, \" | Mean rewards: \", np.mean(rewards), \" | Mean of top 5: \",np.mean(top_rewards[:5]))\n",
    "    #print(rewards)\n",
    "    print(\"Top \",top_limit,\" scores\", sorted_parent_indexes)\n",
    "    print(\"Rewards for top: \",top_rewards)\n",
    "\n",
    "    # setup an empty list for containing children agents\n",
    "    children_agents, elite_index = return_children(agents, sorted_parent_indexes, elite_index)\n",
    "\n",
    "    plot_elite(children_agents[elite_index],log, generation)\n",
    "\n",
    "    # kill all agents, and replace them with their children\n",
    "    agents = children_agents\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%#%%"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}